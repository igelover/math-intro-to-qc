{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dba718d",
   "metadata": {},
   "source": [
    "<a href=\"https://qworld.net\" target=\"_blank\" align=\"left\"><img src=\"../qworld/images/header.jpg\"  align=\"left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff6a6e",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "_prepared by Israel Gelover_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff787c55",
   "metadata": {},
   "source": [
    "Currently we have a paradigm of **Classical Computing** whose implementation is based on electronics, basically transistors on integrated circuits. The objective of large companies that design processors is precisely to integrate more transistors on smaller circuits. This trend is known as **Moore's Law**, which originally predicted that the number of transistors that can be integrated in a circuit would double every 2 years. Later there was an adjustment to this forecast and the time was reduced to 18 months.\n",
    "\n",
    "The Quantum Computing paradigm has several advantages over classical computing. For example, the possibility of modeling quantum systems naturally, just as Richard Feynmann proposed; task optimization, that is, solving problems that would take too long for a classical computer; etc. However, in this section we will focus on motivation: **Why do we need quantum computing?**\n",
    "\n",
    "On one hand, due to the limitations of the physical implementation that we have for clasical computing, bit operations using voltage, i.e. the limitations of the implementation based on electronics. And on the other hand, the problems inherent to the classical paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bb9b4",
   "metadata": {},
   "source": [
    "## Problems due to Implementation\n",
    "\n",
    "<a name=\"remark_1_1\">Remark 1.1</a> Computational power is measured in FLOPS (Floating point operations per second).\n",
    "\n",
    "Let's analyze how computational power has evolved throughout history.\n",
    "\n",
    "| Year | Technology          | Size    | # Transistors | FLOPS  |\n",
    "|:-----|:--------------------|:--------|:--------------|:-------|\n",
    "| 1995 | Vacuum tubes        | ~10 cm  | ~10           | ~10^3  |\n",
    "| 2005 | Integrated circuits | ~100 nm | ~10^8         | ~10^13 |\n",
    "| 2018 | Integrated circuits | ~12 nm  | ~10^10        | ~10^15 |\n",
    "\n",
    "- Moore's Law (1965): The number of transistors that can be integrated in a circuit doubles every 2 years.\n",
    "- Moore's Law (1975): The number of transistors that can be integrated in a circuit doubles every 18 months.\n",
    "- Around 2000, it was noted that this growth started to slow down, so in 2007 an expiration date was proposed for Moore's law, this was predicted between years 2017-2022.\n",
    "- Moore's Law is still in effect but...\n",
    "    - In short time, atomic sizes will be reached and quantum effects will be dominant.\n",
    "    - Thermal noise increases as the size decreases and the density of the components increases.\n",
    "    - Heat generation is increasing and its dissipation is increasingly difficult.\n",
    "    - Electronics inherently generates heat and the process of erasing information generates heat as well. The entropy of a system is closely related to the information that can be stored in that system and deleting information increases the entropy of the system, that is, it generates heat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713f289",
   "metadata": {},
   "source": [
    "## Problems of the Classical Paradigm\n",
    "\n",
    "<a name=\"remark_1_2\">Remark 1.2</a> Problems of the Classical Paradigm.\n",
    "\n",
    "- Limitations of AI (Machine Learning & Deep Learning): They are not multitasking, they are designed to solve limited tasks. They do not explain, explainability is currently an open problem. They need to be \"massively parallel\", but this conflicts with the next bullet point.\n",
    "- It is sequential (it is not parallel), although there are processors with several cores and different tasks can be parallelized, the classical paradigm itself is sequential. There are limitations of this parallelization, for example, two nested functions cannot be parallelized, and this is not a hardware problem, but rather an implementation problem due to the classical paradigm itself.\n",
    "\n",
    "In summary: **We need to find an alternative.**\n",
    "\n",
    "In order to aleviate the problems due to implementation that we just listed, there are several proposals for alternative paradigms to perform computation. To name a few: bacterial computation, probabilistic computation, analog computation, spintronics (spin transport electronics) or spin electronics, etc. However, Quantum Computing is one that currently is most spread amomg the scientific community and even with a lot of financial help from large companies such as IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f3015",
   "metadata": {},
   "source": [
    "## Advantages of Quantum Computing\n",
    "\n",
    "- Quantum Computing is inherently parallel computation. We will delve into this point later, but this intrinsic parallelism is due to the superposition of states. At the end of a quantum algorithm, a measurement will only recover one state, however the operations carried out by the algorithm are carried out with each of the elements of the superposition.\n",
    "- No heat dissipation. The entropy of the system is not increased since information is not erased. Information is maintained in quantum mechanics, it can be transformed by unitary operators but not erased.\n",
    "- Natural simulation of quantum systems. As Feynmann proposed it, this is due to the very nature of the quantum paradigm, since quantum systems are used to model another quantum system, basically what we have is a scale model of the initial problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46989ffc",
   "metadata": {},
   "source": [
    "## NISQ Era (Noisy Intermediate-Scale Quantum)\n",
    "\n",
    "All the quantum computers that have been built so far serve very specific purposes, there is no such thing as a multipurpose quantum computer. We are speaking of devices that use properties of quantum mechanics to perform operations very quickly. A clear example of this is the quantum computer created in China that recently claimed quantum supremacy, this machine is designed to solve a specific problem and serves exclusively to solve that problem.\n",
    "\n",
    "What is currently being sought is to create a multipurpose quantum computer, however there are a number of technological challenges.\n",
    "\n",
    "- Control of the evolution of the components. The basic unit of information in quantum computing is a two-level quantum state that we call _qubit_. There are different ways of modeling these qubits, with a photon, with an electron, with an anion, etc; and regardless of the physical system used to model them, it is necessary to control their temporal evolution. This control in the evolution of the components essentially limits the number of qubits a quamtum computer can have. Currently, around 100 qubits can be controlled for a certain period of time (which is sufficient to perform operations moderately efficiently).\n",
    "- Decoherence. It is the information decay due to interaction with the environment. For example, a qubit can be encoded with the spin of a photon and sent through a fiber optic cable, but regardless of the quality of the fiber optic, as the photon advances, the probability of measuring the information that was encoded in it decreases until it becomes random. Therefore, it is necessary to process this information, that is, to execute the algorithm that has been programmed, in a sufficiently short time to avoid this decay.\n",
    "\n",
    "These two previous points mark the era of quantum computing that we are in, which is known as the NISQ (Noisy Intermediate-Scale Quantum) Era. Intermediate-Scale refers to the size of quantum computers that will be available in the medium term of the next few years, with a number of qubits between 50 and a few hundred. Noisy emphasizes the fact that we will have imperfect control over qubits, this represents serious limitations on what these devices will be able to achieve in the near future. All algorithms developed in this era must take into account these limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddd4d2",
   "metadata": {},
   "source": [
    "## Additional benefits\n",
    "\n",
    "What else do we get from having this smallest unit of quantum information (the two-level quantum state that we call a qubit)?\n",
    "\n",
    "- Teleportation. The quantum information contained in a qubit is encoded in classical bits that are sent through a traditional or classical channel, to later recreate the information quantum, that is, recreate the qubit.\n",
    "- Superdense coding. This is essentially the reverse process of teleportation, that is, two classical bits are encoded into a single qubit, to be recovered later.\n",
    "- Quantum cryptography. The RSA algorithm is based on factoring very large integers into their prime factors, which is very expensive in terms classical computing. Shor's algorithm offers a much faster way to do this factoring, which has serious implications for classical cryptography."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
